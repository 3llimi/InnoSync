---
weight: 1
bookFlatSection: true
title: "To be announced - Identification of compounds"
---

# **To be announced - Identification of compounds**

# **Week #1 Progress report**

## **Team Formation and Project Proposal**

### **Team Members**

| Team Member        | Telegram ID | Email Address                     |
|--------------------|-------------|-----------------------------------|
| Evgenij Ivankin    | eugen_iv    | e.ivankin@innopolis.university    |
| Vitaly Mahonin     | tNabuki     | v.mahonin@innopolis.university    |
| Timolai Andrievich | tandrievich | t.andrievich@innopolis.university |

## **Value Proposition**

### Identify the Problem:
For decades, chemical scientists and students have wasted their time on converting compound representations from one form to another. It is not only a problem of wasting several minutes per formula, but also the fact that the algorithms for such conversions are pretty complex and require students to study them for about half a year before they can be applied. Even experienced scientists can make errors due to human factors, so double-checking the formula is usually required. People also tend to forget things, so they need to restudy the algorithm from time to time. Additionally, sometimes even non-chemistry people need to do some chemistry, but the main obstacle for them may be not knowing how to identify the name of the molecule from a drawing, as well as not having enough time to learn how to do it.

### Solution Description:
To provide the most user-friendly experience possible, we need a mobile application that can instantly name a compound and provide its simple string notation (e.g. SMILES/InChl/IUPAC) by just taking a picture of its graphical representation.

### Benefits to Users:
With this solution all three groups of users will be satisfied:
- Scientists will no longer waste their precious time doing mechanical work.
- Students can study less boring material.
- Non-chemistry people now have no barriers to doing basic chemistry.

### Differentiation:
There are already some applications that solve a part of this problem. The closest analog is the "Organic Compound Identifier" app, but it does not detect the compound from the photo/drawing. Rather, it prompts the user to input the formula in the graph form by placing predetermined blocks of atoms and then connecting them. It is also limited to organic compounds only. Our application, on the other hand, is general-purpose for any compound, faster to apply, and easier to use.

### User Impact:
The major impact is made on students. While they still need to study the principles of compound representation conversions, now knowing only the essentials reduces the half-year course to several weeks. Scientists will be able to concentrate more on the research they are doing, spending no time identifying and searching for molecules in the database by hand. Lastly, now even inexperienced people can be involved in some parts of science.

Overall, all the positive impact leads us to a faster growth of this science in both aspects: study and researching, as well as simplification of some domains of chemistry.

### Use Cases:
1. Scientist
- A chemical scientist working on a research project needs to identify a compound from a graphical representation. She opens the app, takes a picture of the compound, and obtains its name and linear notation instantly, saving her time and effort.
- Another chemical scientist is looking at a molecule structure in a conference presentation but cannot recognize it. He quickly takes a photo of it using the app and gets an accurate name and SMILES string.

2. Students
- A chemistry student is practicing identifying compounds from graphical representations as part of their homework assignment. Instead of manually converting them one by one, he uses the app to take photos of each one and quickly get their names and SMILES notations.
- While studying for an exam, a chemistry student comes across a compound that she is unfamiliar with. She scans its representation into the app, receives its name and SMILES string, and can continue with her studies.

3. Non-Chemistry people
- A user is browsing social media and sees an interesting post about a molecular structure. They snap a picture of it, and the app identifies the compound, providing them with its name and SMILES notation, which they can then share with others or look up for more information.
- A person is planning a DIY home project that involves using different chemicals. Given the idea, they saw in a chemistry book, but it was made for professionals and some compounds are just drawn with no naming. So they can use this app to easily determine the names of the needed compounds (or if there is no name, just SMILES notation), so now they can search for them on the internet.

## **Lean Startup Questionnaire**

1. What problem or need does your software project address?
> Our software project addresses the problem of wasting time and effort in converting organic compound representations from one form to another. It also aims to simplify the identification of compounds from graphical representations, making it easier for non-chemistry people to do basic chemistry.
2. Who are your target users or customers?
> Our target users are chemical scientists, students, and non-chemistry people who need to identify compounds from graphical representations.
3. How will you validate and test your assumptions about the project?
> We plan to validate and test our assumptions by conducting user interviews, surveys, and usability testing. We will gather feedback from early adopters and iterate accordingly.
4. What metrics will you use to measure the success of your project?
> The metrics we will use to measure the success of our project include user engagement (number of active users, frequency of app use), user satisfaction (ratings and reviews), and conversion rates (number of paid subscribers).
5. How do you plan to iterate and pivot if necessary based on user feedback?
> We plan to iterate and pivot based on user feedback by regularly collecting user feedback through surveys and usability testing. We will prioritize feature requests and bug fixes based on user impact and implement changes in iterative releases. If necessary, we are open to pivoting our product strategy or target market based on data-driven insights.

## **Leveraging AI, Open-Source, and Experts**

- AI (Artificial Intelligence):
> We aim to use AI tools such as Copilot, Tabnine, ChatGPT and others during the development process.
- Open-Source:
> We will utilize publicly-available research in our area to develop an efficient AI that meets the requirements of our target audience.
- Experts in relevant domains:
> We plan to leverage experts in relevant domains by engaging them to provide insights, suggestions, and feedback on our product design and functionality.

## **Inviting Other Students**

We are **NOT** looking for new teammates.

## **Defining the Vision for Your Project**

### Overview:
- Summary:
Our project is a software program that uses AI to convert images into SMILES notation, a simplified chemical representation. The purpose of this program is to make it easier for researchers and scientists to translate chemical structures in images into a format that can be easily analyzed and shared.

- Problem or Need:
Analyzing chemical structures from images is a time-consuming and error-prone process, which can slow down research and prevent scientific breakthroughs. Our project addresses this problem by providing a fast and accurate way to convert chemical structures in images into SMILES notation, which can be easily analyzed and shared among researchers and scientists.

- Benefits and Impact:
By providing a more efficient way to analyze chemical structures in images, our software program will save researchers and scientists valuable time and resources. Additionally, the accuracy of the program will reduce errors in data analysis, leading to more reliable results and faster scientific discoveries. Ultimately, our project will have a positive impact on the scientific community by promoting greater collaboration and knowledge sharing.

### Schematic Drawings:
![](https://i.ibb.co/DrvPS1T/Screenshot-from-2023-06-10-22-37-50.png)

### Tech Stack:
Based on the project requirements, team expertise, and considerations for scalability, performance, security, and ease of development, we have decided to utilize the following technologies, frameworks, and programming languages in our project:

Python: We will be using Python and PyTorch for neural net model development. Python is a popular and powerful programming language that has strong support for data analysis, machine learning, and artificial intelligence. Our team is experienced in Python and it is well-suited for building complex models quickly and efficiently. It also provides many useful libraries and packages such as NumPy, Pandas, and TensorFlow, which further enhances our productivity, reliability, and accuracy.

Flutter: We will be using Flutter for our mobile application UI. Flutter is a modern and versatile framework that allows us to build beautiful, responsive, and performant interfaces for both Android and iOS platforms with a single codebase. It is written in Dart, a fast and easy-to-learn programming language that enables us to create robust and flexible applications. This choice not only allows us to simplify the development process by minimizing the maintenance cost and testing efforts but it also ensures a high-quality user experience across different devices.

Overall, this tech stack provides an efficient, effective, and sustainable way to meet our project goals and challenges. It leverages the strengths and expertise of our team members while taking into account the needs and expectations of our target users. We are confident that by utilizing Python for model development and Flutter for mobile UI, we can deliver a top-notch product that meets the highest standards of quality and innovation.

### Anticipating Future Problems:
During the project development and deployment phases, we anticipate a few potential challenges and obstacles that could arise:

1. Technical complexities - As our model may be big and slow, it may take a lot of time and resources to train and evaluate it. This can affect the overall performance and scalability of our application. Additionally, integrating a complex model with the mobile application UI can be technically challenging and may require significant modifications to the existing codebase.

Mitigation strategy: To address these challenges, we will consider optimizing our model by reducing its size and improving its processing speed. We may also explore using pre-trained models or, in the worst case we plan to use cloud-based services (because the main point is to remain autonomus) to offload some of the computational workload. Furthermore, we can break down the integration process into smaller, manageable tasks that can be implemented incrementally and tested thoroughly.

2. External dependencies - Our project may depend on external factors such as third-party APIs, data sources, or platform-specific requirements. Any changes or disruptions in these dependencies can impact the functionality and reliability of our application.
Mitigation strategy: To mitigate these risks, we will ensure that we use reliable and trustworthy APIs and data sources that have sufficient documentation and support. We will also have fallback plans in place in case of any disruptions or changes in these dependencies. Additionally, we can test our application on multiple platforms and devices to identify and address any compatibility issues before the final release.

Overall, by anticipating these potential challenges and proposing appropriate mitigation strategies, we can minimize the risks and uncertainties associated with the project development and deployment phases. We can also ensure that our team is prepared to tackle any issues that may arise during the process and deliver a successful product that meets the needs and expectations of our users.

### Elaborate Explanations:
The core functionality of our application lies in its image processing and classification capabilities. By taking advantage of state-of-the-art machine learning techniques, we are able to achieve high levels of accuracy and speed, making the process of identifying chemical compounds as seamless as possible. Our mobile application has an intuitive user interface that makes it easy for anyone to use, regardless of technical background.

One of the unique aspects of our solution compared to existing alternatives is its broad scope. Unlike other applications that are specific to organic compounds or have limited functionality, ours is designed to work with any type of molecule. Additionally, our application uses innovative techniques such as deep learning and image processing to provide accurate results quickly and efficiently. We believe that our solution will revolutionize the way people think about chemistry and make it accessible to a wider audience.

{{< hint danger >}}
**Feedback**  
I think this is a wonderful project that can benefit a lot of professional chemists and students. Conversion of complicated graphical representations into name of the compound is an interesting technical project that involves a lot of different technologies. 

Overall, your report effectively presents a problem-solution approach and conveys the potential impact and benefits of the proposed mobile application. It would be valuable to further elaborate on the implementation plan, including the technology stack, development roadmap, and potential challenges to be addressed. 

{{< /hint >}}

# **Week #2 Progress report**
## **Tech Stack Selection**

We have already chosen our tech stack on week 1 and decided to keep it.

## **Architecture Design**

1. **Component Breakdown**: There are two basic components: UI and AI, which interact in a request-response manner. The UI requests to analyze a taken photo, and the AI responds with the detected SMILES/InChl/IUPAC notations.

2. **Data Management**: The UI module is supposed to store some user settings, which will be stored using *Hive*. We don't need any database for the AI component as it is self-sufficient.

3. **User Interface (UI) Design**:

There wil be two basic screens:

### Shot screen
![](https://i.ibb.co/GMQz5xL/shot.png)

### Analysis result screen
![](https://i.ibb.co/ZB2wtm7/res.png)

4. **Integration and APIs**: Our application is designed to be fully autonomous, so we will not use any external APIs.

5. **Scalability and Performance**: There is no scaling problem at all since each application is complete and does not require external resources, so there is nothing to scale. Also we will pay more attention to performance since we are working on mobile app without separated backend.

6. **Security and Privacy**: Since the application is designed to be ready-to-use out of the box without any registration, we have no private data to store anywhere.

7. **Error Handling and Resilience**: We plan to use Firebase Crashlytics to handle application crashes for further analysis and fixes.

8. **Deployment and DevOps**: We plan to use CI/CD to automatically build and deploy new application versions to all distribution platforms, as well as registering new Crashlytics handlers for it on the push into the `main` branch. We will use the `dev` branch for application development.

## **Week 2 questionnaire:**  

1) Tech Stack Resources: We are already familiar with our tech stack so we do not use any books on it.

2) Mentorship Support: We are not seeking a mentor for our project.

3) Exploring Alternative Resources: We are going to use official documentation on Flutter, Python and Pytorch.

4) Identifying Knowledge Gaps: We have no knowledge gaps related to our tech stack. See our team allocation below.

5) Engaging with the Tech Community: We have not engaged with tech community and do not plan to do so.

6) Learning Objectives: We did not set any specific learning objectives.

7) Sharing Knowledge with Peers: We did not organized any knowledge-sharing sessions or discussions, since we do not have teammates unfamiliar with our tech stack.

8) Compensating Lacking Expertise with AI: As mentioned above, we are already familiar with our tech stack, so we did not compensate for any lacking expertise in our tech stack.


## **Tech Stack and Team Allocation**


| Team Member        | Responsibilities | Tech Stack |
|--------------------|------------------|------------|
| Evgenij Ivankin    | AI               | Pytorch    |
| Vitaly Mahonin     | Mobile App       | Flutter    |
| Timolai Andrievich | AI               | Pytorch    |

{{< hint danger >}}
**Feedback**
Overall, the progress report is very short and do not describe your group progress very well. It is good that you feel confident in your tech stack, but it will also be wonderful to see a more detailed description of the work done. If you think this is an easy project and that you and your team knows exactly how it needs to be build, consider adding some features that you haven't implemented before. You may take an opportunity to learn new things and have fun while you building this app.
  
Some specific comments - this project report say that main goal of the app is doing image processing and classification, but no details on the model, ML architecture and data is provided. To mee it seems rather strange, because the main part of this project is the model. Are you taking the open-source model or training your own? Are the pictures provided from the app that you already build or this is a mockup of the app? This report raised more questions than it provides answers, so make sure to provide more details on your next week progress report. 3/5 
{{< /hint >}}