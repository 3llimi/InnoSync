---
title: "Week #4"
---

# **Week #4**

## **External feedback, testing, and Progress report**

##### During this week we managed to get some progress done and gather initial feedback from the people.

- **External feedback**:

    The most crucual feedback we got was the one from our professor (or superviser) - Rustam Lukmanov. He was impressed by the quality imporvement of 3D models that were generated by our main AI pipeline. Additionally, we showed the working pipeline to a people that work in architecture field. Shortly speaking, they were impressed by the ease of use and sufficient quality for the "baseline" model.
<br>

- **Testing**:

    During the testing phase, it was identified that the system was not compatible with older versions of Python. Additionally, a couple of minor bugs were detected, affecting both the machine learning pipeline and the API. These issues were thoroughly investigated and successfully addressed, ensuring smoother operation across all supported platforms.
<br>

- **Iteration and Refinement**:
    Iteration and Refinement Report
    This week, our team focused on significant enhancements and refinements in our project, which are detailed below:

    - Model Replacement:
    We replaced the wonder3d model with the microdreamer model. The microdreamer model offers faster inference and higher generation quality compared to wonder3d.
<br>
    - Pipeline Improvement:
    During the pipeline creation, we decided to replace the combination of LLM for prompt engineering and stable diffusion 1.5 with stable diffusion 3. This decision was based on stable diffusion 3's superior ability to understand prompts with 'white background,' which is crucial for our model.
<br>
    - 3D Model Export Fix:
    We addressed and resolved the issue of incorrect 3D model exports using trimesh. As a result, the quality of the models is now considered acceptable for a prototype.
<br>
    - Quality vs. Inference Time:
    While the output quality of the 3D models can be slightly improved by increasing the number of iterations, this also leads to increased inference time.
<br>
    - API Development:
    Our team developed the first basic API using FastAPI. Currently, the API supports a single request: it takes a prompt as input and returns a 3D model.

    Overall, these iterations and refinements have significantly improved the functionality and performance of our project, moving us closer to a robust and      efficient prototype.
<br>

Here are some generated 3D models using the updated pipeline:

![House_V2](/static/2024/OmniShaper/Models_V2/House.gif)
![Mushroom_girl](/static/2024/OmniShaper/Models_V2/Mushroom_girl.gif)

### **Challenges & Solutions**
The hardest challenge was to test and implement the working idea (out of 3) and get the first results.
Another difficult challenge is to find suitable open source models for each of the pipeline. 
And "prompt-engineering", of course...

### **Conclusions & Next Steps**
On the next week we are planning to completely finish our AI pipeline, convert currently existing solution into a working prototype, and set up a correct UI/UX design for the web application.
